{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_Advection(frame_a,frame_b):\n",
    "    # High pass the images to make sure the tracking is not of wave velocity itself\n",
    "    frame_a_hp = frame_a.copy() - smoo(frame_a, 10)\n",
    "    frame_b_hp = frame_b.copy() - smoo(frame_b, 10)\n",
    "\n",
    "    winsize = 36 # pixels, interrogation window size in frame A\n",
    "    searchsize = 36  # pixels, search in image B big enough to contain credible velocity \n",
    "    overlap = 18 # pixels, 50% overlap if half of winsize\n",
    "    dt = 1 # time interval between images, converts pixel displacement to velocity\n",
    "\n",
    "    # Coordinates of velocity positions in image array\n",
    "    x, y = pyprocess.get_coordinates(image_size=frame_a.shape, \n",
    "                                    search_area_size=searchsize, \n",
    "                                    overlap=overlap )\n",
    "\n",
    "    # Use high-pass images as the PIV source frame_a_hp, frame_b_hp\n",
    "\n",
    "    u, v, sig2noise = pyprocess.extended_search_area_piv(  frame_a_hp.astype(np.int32), \n",
    "                                                        frame_b_hp.astype(np.int32), \n",
    "                                                        window_size=winsize, \n",
    "                                                        overlap=overlap, \n",
    "                                                        dt=dt, \n",
    "                                                        search_area_size=searchsize, \n",
    "                                                        sig2noise_method='peak2mean')\n",
    "    # return u/dt, v/dt, sig2noise\n",
    "\n",
    "    mask = validation.global_std(u, v, std_threshold=3)\n",
    "    #replace outliers with NaNs\n",
    "    u[mask] = np.nan\n",
    "    v[mask] = np.nan\n",
    "\n",
    "    mask = validation.global_std(u, v, std_threshold=3)\n",
    "    #replace outliers with NaNs\n",
    "    u[mask] = np.nan\n",
    "    v[mask] = np.nan\n",
    "\n",
    "    u, v = filters.replace_outliers( u, v, mask,\n",
    "                                    method='localmean', \n",
    "                                    max_iter=7, \n",
    "                                    kernel_size=7)\n",
    "    \n",
    "    x, y, u, v = tools.transform_coordinates(x, y, u, v)\n",
    "\n",
    "    # sum/num will be the average, just remember to avoid zero division\n",
    "    a2sum = frame_a.copy()*0.0\n",
    "    a2num = frame_a.copy()*0\n",
    "\n",
    "    # u and v offsets in nearest pixel, integer\n",
    "    xi = x.round().astype(int).ravel()\n",
    "    yi = y.round().astype(int).ravel()\n",
    "    ui = u.round().astype(int).ravel()\n",
    "    vi = v.round().astype(int).ravel()\n",
    "\n",
    "\n",
    "    # Loop over all the little windows in a and add them into a2 \n",
    "    for idx,vpoint in enumerate(xi.ravel()):\n",
    "        windowa = (slice(yi[idx]-winsize//2, yi[idx]+winsize//2,1), \n",
    "                slice(xi[idx]-winsize//2, xi[idx]+winsize//2,1) ) # source image\n",
    "\n",
    "        windowa2= (slice(yi[idx]-winsize//2 + -vi[idx], \n",
    "                        yi[idx]+winsize//2 + -vi[idx],1), \n",
    "                slice(xi[idx]-winsize//2 + ui[idx], \n",
    "                        xi[idx]+winsize//2 + ui[idx],1) ) # where to put it\n",
    "        \n",
    "        try: \n",
    "            a2sum[windowa2] += frame_a[windowa]\n",
    "            a2num[windowa2] += 1\n",
    "        except: \n",
    "            continue\n",
    "            \n",
    "    a2 = (a2sum/(a2num \n",
    "                +0.000001)) # avoid division by zero\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Show_Advection(frame_a, frame_b):\n",
    "    \n",
    "    plt.figure(figsize=[10,5])\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(frame_a); plt.title('original frame'); plt.clim(0,200)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(Calculate_Advection(frame_a, frame_b)); plt.title('advected frame'); plt.clim(0,200)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(frame_b); plt.title('original next frame'); plt.clim(0,200)\n",
    "\n",
    "def Estimate_Advection(frame_a,frame_b):\n",
    "\n",
    "    plt.figure(figsize=[10,5])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(Calculate_Advection(frame_a, frame_b)); plt.title('advected frame'); plt.clim(0,200); plt.colorbar(shrink=0.5)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(frame_b-Calculate_Advection(frame_a, frame_b),cmap='bwr'); plt.title('Next Frame - Advected Frame'); plt.clim(-50,50); plt.colorbar(shrink=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for constructing wavenumber and angle, for filtering masks \n",
    "def distance_from(a, index):\n",
    "    i,j = np.indices(a.shape, sparse=True)\n",
    "    return np.sqrt((i-index[0])**2 + (j-index[1])**2)\n",
    "\n",
    "def angle_from(a, index):\n",
    "    i,j = np.indices(a.shape, sparse=True)\n",
    "    return np.arctan2((j-index[1]),(i-index[0]))\n",
    "\n",
    "def Show_Brightness(frame_a,frame_b):\n",
    "    # Fourier transform and shift to center and total wavenumber array kl\n",
    "    diff = frame_b-frame_a\n",
    "    diffhat = np.fft.fftshift(np.fft.fft2(diff))\n",
    "\n",
    "    # Power\n",
    "    power = np.abs(diffhat)**2\n",
    "\n",
    "    # Wavenumbers \n",
    "    kl = distance_from(diffhat, [diffhat.shape[0]/2, diffhat.shape[1]/2] )\n",
    "\n",
    "    mask = (  (kl>0) & (kl<=10) ) \n",
    "\n",
    "    recon = np.fft.ifft2( np.fft.ifftshift( diffhat*mask ))\n",
    "\n",
    "    plt.imshow(recon.real, cmap='RdBu_r')\n",
    "    plt.clim(-20,20); plt.colorbar(shrink=0.7); plt.title('filtered d/dt(brightness)')\n",
    "\n",
    "def Show_Convergence(frame_a,frame_b,SmoothBorders=False):\n",
    "    # High pass the images to make sure the tracking is not of wave velocity itself\n",
    "    frame_a_hp = frame_a.copy() - smoo(frame_a, 10)\n",
    "    frame_b_hp = frame_b.copy() - smoo(frame_b, 10)\n",
    "\n",
    "    winsize = 36 # pixels, interrogation window size in frame A\n",
    "    searchsize = 36  # pixels, search in image B big enough to contain credible velocity \n",
    "    overlap = 18 # pixels, 50% overlap if half of winsize\n",
    "    dt = 1 # time interval between images, converts pixel displacement to velocity\n",
    "\n",
    "    # Coordinates of velocity positions in image array\n",
    "    x, y = pyprocess.get_coordinates(image_size=frame_a.shape, \n",
    "                                    search_area_size=searchsize, \n",
    "                                    overlap=overlap )\n",
    "\n",
    "    # Use high-pass images as the PIV source frame_a_hp, frame_b_hp\n",
    "\n",
    "    u, v, sig2noise = pyprocess.extended_search_area_piv(  frame_a_hp.astype(np.int32), \n",
    "                                                        frame_b_hp.astype(np.int32), \n",
    "                                                        window_size=winsize, \n",
    "                                                        overlap=overlap, \n",
    "                                                        dt=dt, \n",
    "                                                        search_area_size=searchsize, \n",
    "                                                        sig2noise_method='peak2mean')\n",
    "\n",
    "    mask = validation.global_std(u, v, std_threshold=3)\n",
    "    #replace outliers with NaNs\n",
    "    u[mask] = np.nan\n",
    "    v[mask] = np.nan\n",
    "\n",
    "    mask = validation.global_std(u, v, std_threshold=3)\n",
    "    #replace outliers with NaNs\n",
    "    u[mask] = np.nan\n",
    "    v[mask] = np.nan\n",
    "\n",
    "    u, v = filters.replace_outliers( u, v, mask,\n",
    "                                    method='localmean', \n",
    "                                    max_iter=7, \n",
    "                                    kernel_size=7)\n",
    "    \n",
    "    x, y, u, v = tools.transform_coordinates(x, y, u, v)\n",
    "\n",
    "    divx = np.gradient(u)[1]\n",
    "    divy = -np.gradient(v)[0]\n",
    "    div = divx+divy\n",
    "    if SmoothBorders == True:\n",
    "        window = np.hanning(8)  # 8 pixels wide hanning window (4*2)\n",
    "\n",
    "        # Apply the window to top and bottom borders\n",
    "        div[:4, :] = div[:4, :] * window[:4, None]\n",
    "        div[-4:, :] = div[-4:, :] * window[:4, None]\n",
    "\n",
    "        # Apply the window to left and right borders\n",
    "        div[:, :4] = div[:, :4] * window[:4, None].T\n",
    "        div[:, -4:] = div[:, -4:] * window[:4, None].T\n",
    "\n",
    "        plt.imshow(smoo(-div, 2), cmap='RdBu_r', clim=[-0.2,0.2]); plt.colorbar(shrink=0.7)\n",
    "        plt.title('convergence of PIV velocities')  \n",
    "    else:\n",
    "        plt.imshow(smoo(-div, 2), cmap='RdBu_r', clim=[-1,1]); plt.colorbar(shrink=0.7)\n",
    "        plt.title('convergence of PIV velocities')    \n",
    "\n",
    "def Show_Contour(frame_a,frame_b,SmoothBorders=False):\n",
    "    # High pass the images to make sure the tracking is not of wave velocity itself\n",
    "    frame_a_hp = frame_a.copy() - smoo(frame_a, 10)\n",
    "    frame_b_hp = frame_b.copy() - smoo(frame_b, 10)\n",
    "\n",
    "    winsize = 36 # pixels, interrogation window size in frame A\n",
    "    searchsize = 36  # pixels, search in image B big enough to contain credible velocity \n",
    "    overlap = 18 # pixels, 50% overlap if half of winsize\n",
    "    dt = 1 # time interval between images, converts pixel displacement to velocity\n",
    "\n",
    "    # Use high-pass images as the PIV source frame_a_hp, frame_b_hp\n",
    "\n",
    "    u, v, sig2noise = pyprocess.extended_search_area_piv(  frame_a_hp.astype(np.int32), \n",
    "                                                        frame_b_hp.astype(np.int32), \n",
    "                                                        window_size=winsize, \n",
    "                                                        overlap=overlap, \n",
    "                                                        dt=dt, \n",
    "                                                        search_area_size=searchsize, \n",
    "                                                        sig2noise_method='peak2mean')\n",
    "    # Coordinates of velocity positions in image array\n",
    "    x, y = pyprocess.get_coordinates(image_size=frame_a.shape, \n",
    "                                    search_area_size=searchsize, \n",
    "                                    overlap=overlap )\n",
    "\n",
    "    mask = validation.global_std(u, v, std_threshold=3)\n",
    "    #replace outliers with NaNs\n",
    "    u[mask] = np.nan\n",
    "    v[mask] = np.nan\n",
    "\n",
    "    mask = validation.global_std(u, v, std_threshold=3)\n",
    "    #replace outliers with NaNs\n",
    "    u[mask] = np.nan\n",
    "    v[mask] = np.nan\n",
    "\n",
    "    u, v = filters.replace_outliers( u, v, mask,\n",
    "                                    method='localmean', \n",
    "                                    max_iter=7, \n",
    "                                    kernel_size=7)\n",
    "    \n",
    "    x, y, u, v = tools.transform_coordinates(x, y, u, v)\n",
    "\n",
    "    divx = np.gradient(u)[1]\n",
    "    divy = -np.gradient(v)[0]\n",
    "    div = divx+divy\n",
    "    if SmoothBorders == True:\n",
    "        # transform the first 4 rows and columuns into NaN\n",
    "        window = np.hanning(8)  # 8 pixels wide hanning window (4*2)\n",
    "\n",
    "        # Apply the window to top and bottom borders\n",
    "        div[:4, :] = div[:4, :] * window[:4, None]\n",
    "        div[-4:, :] = div[-4:, :] * window[:4, None]\n",
    "\n",
    "        # Apply the window to left and right borders\n",
    "        div[:, :4] = div[:, :4] * window[:4, None].T\n",
    "        div[:, -4:] = div[:, -4:] * window[:4, None].T\n",
    "\n",
    "\n",
    "    # Fourier transform and shift to center and total wavenumber array kl\n",
    "    diff = frame_b-frame_a\n",
    "    diffhat = np.fft.fftshift(np.fft.fft2(diff))\n",
    "\n",
    "    # Wavenumbers \n",
    "    kl = distance_from(diffhat, [diffhat.shape[0]/2, diffhat.shape[1]/2] )\n",
    "\n",
    "    mask = (  (kl>0) & (kl<=10) ) \n",
    "\n",
    "    recon = np.fft.ifft2( np.fft.ifftshift( diffhat*mask ))\n",
    "\n",
    "    plt.pcolormesh(recon.real, cmap='RdBu_r')\n",
    "    plt.clim(-20,20); plt.title('d/dt(brightness) and conv(PIV wind)')\n",
    "\n",
    "    plt.contour(x,y, np.flipud(smoo(-div, 2)), levels=(-5+np.arange(11))/20., cmap='RdBu_r')\n",
    "    if SmoothBorders == False:\n",
    "        plt.ylim(950,50); plt.xlim(500,1400)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Matrices(frame_a,frame_b):\n",
    "    # High pass the images to make sure the tracking is not of wave velocity itself\n",
    "    frame_a_hp = frame_a.copy() - smoo(frame_a, 10)\n",
    "    frame_b_hp = frame_b.copy() - smoo(frame_b, 10)\n",
    "\n",
    "    winsize = 36 # pixels, interrogation window size in frame A\n",
    "    searchsize = 36  # pixels, search in image B big enough to contain credible velocity \n",
    "    overlap = 18 # pixels, 50% overlap if half of winsize\n",
    "    dt = 1 # time interval between images, converts pixel displacement to velocity\n",
    "\n",
    "    # Use high-pass images as the PIV source frame_a_hp, frame_b_hp\n",
    "\n",
    "    u, v, sig2noise = pyprocess.extended_search_area_piv(  frame_a_hp.astype(np.int32), \n",
    "                                                        frame_b_hp.astype(np.int32), \n",
    "                                                        window_size=winsize, \n",
    "                                                        overlap=overlap, \n",
    "                                                        dt=dt, \n",
    "                                                        search_area_size=searchsize, \n",
    "                                                        sig2noise_method='peak2mean')\n",
    "    # Coordinates of velocity positions in image array\n",
    "    x, y = pyprocess.get_coordinates(image_size=frame_a.shape, \n",
    "                                    search_area_size=searchsize, \n",
    "                                    overlap=overlap )\n",
    "\n",
    "    mask = validation.global_std(u, v, std_threshold=3)\n",
    "    #replace outliers with NaNs\n",
    "    u[mask] = np.nan\n",
    "    v[mask] = np.nan\n",
    "\n",
    "    mask = validation.global_std(u, v, std_threshold=3)\n",
    "    #replace outliers with NaNs\n",
    "    u[mask] = np.nan\n",
    "    v[mask] = np.nan\n",
    "\n",
    "    u, v = filters.replace_outliers( u, v, mask,\n",
    "                                    method='localmean', \n",
    "                                    max_iter=7, \n",
    "                                    kernel_size=7)\n",
    "    \n",
    "    x, y, u, v = tools.transform_coordinates(x, y, u, v)\n",
    "\n",
    "    divx = np.gradient(u)[1]\n",
    "    divy = -np.gradient(v)[0]\n",
    "    div = divx+divy\n",
    "\n",
    "    # Fourier transform and shift to center and total wavenumber array kl\n",
    "    diff = frame_b-frame_a\n",
    "    diffhat = np.fft.fftshift(np.fft.fft2(diff))\n",
    "\n",
    "    # Wavenumbers \n",
    "    kl = distance_from(diffhat, [diffhat.shape[0]/2, diffhat.shape[1]/2] )\n",
    "\n",
    "    mask = (  (kl>0) & (kl<=10) ) \n",
    "\n",
    "    recon = np.fft.ifft2( np.fft.ifftshift( diffhat*mask ))\n",
    "\n",
    "    return smoo(-div, 2), recon.real\n",
    "\n",
    "def resize_matrix(original, target_dimensions):\n",
    "    original, target = Get_Matrices(frame_a, frame_b)\n",
    "\n",
    "    # Determine the current dimensions of the original matrix\n",
    "    original_dimensions = original.shape\n",
    "    target_dimensions = target.shape\n",
    "\n",
    "    # Step 1: Define the original grid\n",
    "    x = np.linspace(0, 1, original_dimensions[1])  \n",
    "    y = np.linspace(0, 1, original_dimensions[0])  \n",
    "\n",
    "    # Step 2: Define the function on this grid\n",
    "    X, Y = np.meshgrid(x, y, indexing='ij')\n",
    "    Z = original.T\n",
    "\n",
    "    # Step 3: Create a finer grid for interpolation\n",
    "    x_fine = np.linspace(0, 1, target_dimensions[1])  \n",
    "    y_fine = np.linspace(0, 1, target_dimensions[0])  \n",
    "\n",
    "    # Step 4: Use RegularGridInterpolator\n",
    "    interpolator = RegularGridInterpolator((x, y), Z)\n",
    "    X_fine, Y_fine = np.meshgrid(x_fine, y_fine, indexing='ij')\n",
    "    points_fine = np.array([X_fine.ravel(), Y_fine.ravel()]).T\n",
    "    Z_fine = interpolator(points_fine).reshape(target_dimensions[1], target_dimensions[0])\n",
    "\n",
    "    return Z_fine.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Show_Candidates(frame_a,frame_b,plot_option='no'):\n",
    "    con, bri = Get_Matrices(frame_a,frame_b)\n",
    "    con=resize_matrix(con, bri.shape)\n",
    "\n",
    "    # create a tuple array, that takes for each cell the con and bri values\n",
    "    candidates = np.zeros((con.shape[0], con.shape[1]), dtype=[('con', float), ('bri', float)])\n",
    "    candidates['con'] = con\n",
    "    candidates['bri'] = bri\n",
    "\n",
    "    # Define a threshold for closeness to the 1:1 line\n",
    "    threshold = 0.5  \n",
    "\n",
    "    # Get the points close to the 1:1 line\n",
    "    close_to_line = np.abs(candidates['bri'] - candidates['con']) < threshold\n",
    "\n",
    "    if plot_option == 'yes':\n",
    "        # Scatter plot of con vs bri with the required axis settings and aspect ratio\n",
    "        plt.figure(figsize=(10, 5))  \n",
    "\n",
    "        #plot the close to line in red and the rest in blue\n",
    "        plt.scatter(candidates['bri'][close_to_line], candidates['con'][close_to_line], s=1, color='red')\n",
    "        plt.scatter(candidates['bri'][~close_to_line], candidates['con'][~close_to_line], s=1, color='blue')\n",
    "        plt.xlabel('Brightness')\n",
    "        plt.ylabel('Convergence')\n",
    "\n",
    "        # Adjust axes to be centered on (0, 0)\n",
    "        plt.axhline(0, color='black', linewidth=0.8)\n",
    "        plt.axvline(0, color='black', linewidth=0.8)\n",
    "\n",
    "        # Set the axis limits \n",
    "        plt.xlim(-10, 10)\n",
    "        plt.ylim(-5, 5)\n",
    "\n",
    "        # Plot a line with a slope of 1:1 for convergence:brightness\n",
    "        plt.plot([bri.min(), bri.max()], [bri.min(), bri.max()], 'k--', lw=2)  # Plot a 1:1 line for reference\n",
    "\n",
    "        plt.title('Scatter Plot of Convergence vs. Brightness')\n",
    "        plt.show()\n",
    "\n",
    "    # Retrieve the coordinates of the points close to the 1:1 line\n",
    "    close_points_indices = np.nonzero(close_to_line)\n",
    "    close_points_coordinates = list(zip(close_points_indices[0], close_points_indices[1]))\n",
    "\n",
    "    # plot frame_b with the close points in red\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(frame_b, cmap='gray')\n",
    "    plt.scatter([p[1] for p in close_points_coordinates], [p[0] for p in close_points_coordinates], s=1, color='red')\n",
    "    plt.title('Potential candidates for GW')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames_from_video(video_path, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_path = os.path.join(output_folder, f'frame{count}.png')\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def crop_to_central_data(image_path,number):\n",
    "    \"\"\"\n",
    "    Crop the image to the central data area based on hardcoded coordinates.\n",
    "\n",
    "    :param image_path: Path to the image file.\n",
    "    :return: Cropped Image object.\n",
    "    \"\"\"\n",
    "    crop_coordinates = (125, 120, 900, 890) \n",
    "    with Image.open(image_path) as img:\n",
    "        # Crop the image to the predefined coordinates\n",
    "        # Extract the directory and base name without extension\n",
    "        directory = os.path.dirname(image_path)\n",
    "        base_name = os.path.basename(image_path)\n",
    "        name, extension = os.path.splitext(base_name)\n",
    "\n",
    "        # Create the new file name and save the cropped image\n",
    "        new_file_name = f\"{'image_'}{number}{extension}\"\n",
    "        cropped_img = img.crop(crop_coordinates)\n",
    "        cropped_img.save(os.path.join(directory, new_file_name))\n",
    "\n",
    "# Example usage:\n",
    "#cropped_image = crop_to_central_data(path_to_image,0)\n",
    "# The function calls are commented out to prevent execution in the PCI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fourrier_Analysis(frame):\n",
    "    # FFT2 to identify horizontal wavenumber vector \n",
    "    # ChatGPT wrote this code and I tested/adapted from there \n",
    "\n",
    "    # remove enough colmuns or rows to make it square\n",
    "    if frame.shape[0] > frame.shape[1]:\n",
    "        frame = frame[:frame.shape[1],:]\n",
    "    elif frame.shape[0] < frame.shape[1]:\n",
    "        frame = frame[:,:frame.shape[0]]\n",
    "\n",
    "    cloud_pattern = frame\n",
    "    \n",
    "\n",
    "    # Generate a sample image (replace this with your cloud probability distribution)\n",
    "    image_size = cloud_pattern.shape[0]\n",
    "\n",
    "    # Apply Fourier Transform\n",
    "    fft_result = fft2(cloud_pattern)\n",
    "\n",
    "    # Shift zero frequency components to the center\n",
    "    fft_result_shifted = fftshift(fft_result)\n",
    "\n",
    "    # Calculate amplitude\n",
    "    amplitude = np.abs(fft_result_shifted)\n",
    "\n",
    "\n",
    "    # Create 2D wavenumber array\n",
    "    kx = np.fft.fftshift(np.fft.fftfreq(image_size, d=1/image_size)) \n",
    "    ky = np.fft.fftshift(np.fft.fftfreq(image_size, d=1/image_size))\n",
    "    kx, ky = np.meshgrid(kx, ky)\n",
    "\n",
    "    # Calculate total wavenumber array\n",
    "    wavenumbers = np.sqrt(kx**2 + ky**2)\n",
    "\n",
    "\n",
    "    # Calculate the polar coordinates\n",
    "    radius = np.sqrt(kx**2 + ky**2)\n",
    "    theta = np.arctan2(ky, kx)\n",
    "\n",
    "    # Average the amplitude where the TOTAL wavenumber is between 4 and 20\n",
    "    min_wavenumber = 2\n",
    "    max_wavenumber = 20\n",
    "    in_k_range = (radius>min_wavenumber) & (radius<max_wavenumber)\n",
    "\n",
    "\n",
    "    # Create theta bins\n",
    "    num_bins = 36  # 10 degrees each bin \n",
    "    theta_bins = np.linspace(np.min(theta), np.max(theta), num_bins + 1)\n",
    "\n",
    "    # Calculate the mean amplitude in each theta bin\n",
    "    mean_amplitude = np.zeros(num_bins)\n",
    "    for i in range(num_bins):\n",
    "        in_bin = (theta >= theta_bins[i]) & (theta < theta_bins[i + 1])\n",
    "        mean_amplitude[i] = np.mean(amplitude * in_k_range * in_bin)\n",
    "\n",
    "\n",
    "    # -------- chatGPT fits it, although really just argmax and max-mean suffices \n",
    "    # Define the bisinusoidal fit function\n",
    "    def bisinusoidal_fit(theta, amplitude, phase, offset):\n",
    "        return amplitude * np.sin(2*theta + phase) + offset\n",
    "    # Define the sinusoidal fit function\n",
    "    def sinusoidal_fit(theta, amplitude, phase, offset):\n",
    "        return amplitude * np.sin(theta + phase) + offset\n",
    "\n",
    "    # Initial guess for the fit parameters\n",
    "    initial_guess = [1.0, 0.0, 0.0]\n",
    "\n",
    "    # Fit the sinusoidal curve to the azimuthal variation\n",
    "    popt, _ = curve_fit(bisinusoidal_fit, theta_bins[:-1], mean_amplitude, p0=initial_guess)\n",
    "    # ------------\n",
    "\n",
    "\n",
    "    # Plot the original image, amplitude, the annulus, and the fitted sinusoidal curve\n",
    "    plt.figure(figsize=(16, 4))\n",
    "\n",
    "    plt.subplot(141)\n",
    "    plt.pcolormesh(cloud_pattern, cmap='viridis')\n",
    "    plt.title('Original Image')\n",
    "\n",
    "    plt.subplot(142)\n",
    "    plt.pcolormesh(np.log1p(amplitude), cmap='viridis')\n",
    "    plt.title('Log Amplitude Spectrum')\n",
    "\n",
    "    plt.subplot(143)\n",
    "    plt.pcolormesh(kx,ky, np.log1p(amplitude), cmap='viridis')\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([-30, 30])\n",
    "    ax.set_ylim([-30, 30])\n",
    "    plt.contour(kx,ky,radius, levels=[min_wavenumber, max_wavenumber], colors='r', linewidths=2)\n",
    "    plt.title('Annulus (Wavenumbers 4-20)')\n",
    "\n",
    "    plt.subplot(144)\n",
    "    plt.plot(theta_bins[:-1] *180/3.1415 + 360/num_bins/2, mean_amplitude)\n",
    "    plt.title('amplitude vs. angle in 4-20 wavenumber band')\n",
    "    plt.plot(theta_bins[:-1] *180/3.1415 + 360/num_bins/2, sinusoidal_fit(2*theta_bins[:-1], *popt), 'r-', label='Sinusoidal Fit')\n",
    "\n",
    "    plt.plot() \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    argmx = np.argmax(mean_amplitude)\n",
    "    maxangle = theta_bins[ argmx ]\n",
    "    maxangledeg = theta_bins[ argmx ] *180/3.1415 + 360/num_bins/2\n",
    "\n",
    "    print('angle is ', argmx, maxangle, maxangledeg, maxangledeg+180)\n",
    "    print('strength is ',np.max(mean_amplitude)/np.mean(mean_amplitude) )\n",
    "\n",
    "    # Print the fitted parameters\n",
    "    #amplitude_fit, phase_fit, offset_fit = popt\n",
    "    #print(f\"Amplitude of the Fit: {amplitude_fit}\")\n",
    "    #print(f\"Phase of the Fit: {phase_fit*1800./3.142}\")\n",
    "    #print(f\"Offset of the Fit: {offset_fit}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
